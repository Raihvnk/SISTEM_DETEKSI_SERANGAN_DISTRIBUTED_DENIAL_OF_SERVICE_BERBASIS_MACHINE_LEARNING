{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly_express as px\n",
    "# plt.style.use('default')\n",
    "color_pallete = ['#fc5185', '#3fc1c9', '#364f6b']\n",
    "sns.set_palette(color_pallete)\n",
    "sns.set_style(\"white\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label: DDOS_ICMP\n",
      " datapath_id  version  header_length  tos  total_length  flags  offset  ttl  proto  csum          src_ip   dst_ip  src_port  dst_port  tcp_flag  type_icmp  code_icmp  csum_icmp  port_no  rx_bytes_ave  rx_error_ave  rx_dropped_ave  tx_bytes_ave  tx_error_ave  tx_dropped_ave     label\n",
      "           1        4              5    0            28      0       0  250      1 16079    117.77.2.192 10.0.0.4         0         0         0          8          0      63239        1            42             0               0           118             0               0 DDOS_ICMP\n",
      "           1        4              5    0            28      0       0  250      1 14740 165.203.215.124 10.0.0.4         0         0         0          8        138      63057        1            42             0               0           115             0               0 DDOS_ICMP\n",
      "           1        4              5    0            28      0       0  250      1 20388 109.117.249.194 10.0.0.4         0         0         0          8         87      63176        1            42             0               0           116             0               0 DDOS_ICMP\n",
      "           1        4              5    0            28      0       0  250      1 31728   45.100.13.136 10.0.0.4         0         0         0          8        219      63146        1            42             0               0           118             0               0 DDOS_ICMP\n",
      "           1        4              5    0            28      0       0  250      1 44443     237.63.28.1 10.0.0.4         0         0         0          8        126      62935        1            42             0               0           116             0               0 DDOS_ICMP\n",
      "\n",
      "Label: DDOS_TCP\n",
      " datapath_id  version  header_length  tos  total_length  flags  offset  ttl  proto  csum         src_ip   dst_ip  src_port  dst_port  tcp_flag  type_icmp  code_icmp  csum_icmp  port_no  rx_bytes_ave  rx_error_ave  rx_dropped_ave  tx_bytes_ave  tx_error_ave  tx_dropped_ave    label\n",
      "           1        4              5    0            40      0       0  250      6  5151  91.245.70.183 10.0.0.4       209        80         2          8        181      63016        1            43             0               0           115             0               0 DDOS_TCP\n",
      "           1        4              5    0            40      0       0  250      6 43871   107.98.160.9 10.0.0.4       202        80         2          8        181      63016        1            44             0               0           115             0               0 DDOS_TCP\n",
      "           1        4              5    0            40      0       0  250      6 14775 232.196.148.79 10.0.0.4        39        80         2          8        181      63016        1            44             0               0           115             0               0 DDOS_TCP\n",
      "           1        4              5    0            40      0       0  250      6 27585 185.218.145.47 10.0.0.4       560        80         2          8        181      63016        1            47             0               0           113             0               0 DDOS_TCP\n",
      "           1        4              5    0            40      0       0  250      6 43041   11.229.2.197 10.0.0.4       914        80         2          8        181      63016        1            46             0               0           113             0               0 DDOS_TCP\n",
      "\n",
      "Label: DDOS_UDP\n",
      " datapath_id  version  header_length  tos  total_length  flags  offset  ttl  proto  csum          src_ip   dst_ip  src_port  dst_port  tcp_flag  type_icmp  code_icmp  csum_icmp  port_no  rx_bytes_ave  rx_error_ave  rx_dropped_ave  tx_bytes_ave  tx_error_ave  tx_dropped_ave    label\n",
      "           1        4              5    0            55      0       0   64     17 50258 237.178.190.172 10.0.0.4       476       161         2          8        181      63016        1            54             0               0           113             0               0 DDOS_UDP\n",
      "           1        4              5    0            55      0       0   64     17 41222   230.80.233.90 10.0.0.4       282       161         2          8        199      63268        1            54             0               0           113             0               0 DDOS_UDP\n",
      "           1        4              5    0            55      0       0   64     17 29853     86.4.166.16 10.0.0.4       698       161         2          8        181      63016        1            52             0               0           113             0               0 DDOS_UDP\n",
      "           1        4              5    0            55      0       0   64     17  6509   206.28.137.40 10.0.0.4       367       161         2          8        181      63016        1            48             0               0           113             0               0 DDOS_UDP\n",
      "           1        4              5    0            55      0       0   64     17 17064   88.254.213.11 10.0.0.4       981       161         2          8        181      63016        1            52             0               0           113             0               0 DDOS_UDP\n",
      "\n",
      "Label: NORMAL_ICMP\n",
      " datapath_id  version  header_length  tos  total_length  flags  offset  ttl  proto  csum   src_ip   dst_ip  src_port  dst_port  tcp_flag  type_icmp  code_icmp  csum_icmp  port_no  rx_bytes_ave  rx_error_ave  rx_dropped_ave  tx_bytes_ave  tx_error_ave  tx_dropped_ave       label\n",
      "           1        4              5    0            28      0       0   64      1 26332 10.0.0.2 10.0.0.3       536       161         2          0          0      65205        1            52             0               0           113             0               0 NORMAL_ICMP\n",
      "           1        4              5    0            28      0       0   64      1 26330 10.0.0.4 10.0.0.3       560       161         2          0          0      65343        1            54             0               0           113             0               0 NORMAL_ICMP\n",
      "           1        4              5    0            28      0       0   64      1 26330 10.0.0.3 10.0.0.4       560       161         2          8          0      63039        1            54             0               0           113             0               0 NORMAL_ICMP\n",
      "           1        4              5    0            28      0       0   64      1 26334 10.0.0.1 10.0.0.2       536       161         2          0          0      65457        1            54             0               0           113             0               0 NORMAL_ICMP\n",
      "           1        4              5    0            28      0       0   64      1 26334 10.0.0.1 10.0.0.2       560       161         2          0          0      65435        1            52             0               0           112             0               0 NORMAL_ICMP\n",
      "\n",
      "Label: NORMAL_TCP\n",
      " datapath_id  version  header_length  tos  total_length  flags  offset  ttl  proto  csum   src_ip   dst_ip  src_port  dst_port  tcp_flag  type_icmp  code_icmp  csum_icmp  port_no  rx_bytes_ave  rx_error_ave  rx_dropped_ave  tx_bytes_ave  tx_error_ave  tx_dropped_ave      label\n",
      "           1        4              5    0            40      0       0   64      6 26313 10.0.0.3 10.0.0.4       506       982         0          8          0      63395        1            51             0               0           112             0               0 NORMAL_TCP\n",
      "           1        4              5    0            40      0       0   64      6 26317 10.0.0.1 10.0.0.2       242       541         8          8          0      63395        1            51             0               0           112             0               0 NORMAL_TCP\n",
      "           1        4              5    0            40      0       0   64      6 26313 10.0.0.4 10.0.0.3       833       289         0          8          0      63395        1            52             0               0           112             0               0 NORMAL_TCP\n",
      "           1        4              5    0            40      0       0   64      6 26316 10.0.0.2 10.0.0.2       374       110        32          8          0      63395        1            52             0               0           112             0               0 NORMAL_TCP\n",
      "           1        4              5    0            40      0       0   64      6 26315 10.0.0.4 10.0.0.1        16       566         0          8          0      63373        1            52             0               0           113             0               0 NORMAL_TCP\n",
      "\n",
      "Label: NORMAL_UDP\n",
      " datapath_id  version  header_length  tos  total_length  flags  offset  ttl  proto  csum   src_ip   dst_ip  src_port  dst_port  tcp_flag  type_icmp  code_icmp  csum_icmp  port_no  rx_bytes_ave  rx_error_ave  rx_dropped_ave  tx_bytes_ave  tx_error_ave  tx_dropped_ave      label\n",
      "           1        4              5    0            41      0       0   64     17 26303 10.0.0.3 10.0.0.2       125        56         8          8          0      63395        1            52             0               0           112             0               0 NORMAL_UDP\n",
      "           1        4              5    0            41      0       0   64     17 26303 10.0.0.4 10.0.0.1       441       102         8          8          0      63395        1            52             0               0           112             0               0 NORMAL_UDP\n",
      "           1        4              5    0            41      0       0   64     17 26304 10.0.0.2 10.0.0.2       308       193         8          8          0      63395        1            52             0               0           112             0               0 NORMAL_UDP\n",
      "           1        4              5    0            41      0       0   64     17 26303 10.0.0.4 10.0.0.1       374       146         8          8          0      63373        1            52             0               0           113             0               0 NORMAL_UDP\n",
      "           1        4              5    0            41      0       0   64     17 26302 10.0.0.3 10.0.0.3       160       278         8          8          0      63395        1            52             0               0           112             0               0 NORMAL_UDP\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import dataset\n",
    "dataset = pd.read_csv('datasets.csv')\n",
    "\n",
    "# Kelompokkan data berdasarkan label\n",
    "grouped_data = dataset.groupby('label')\n",
    "\n",
    "# Tampilkan 5 data pertama dari setiap label\n",
    "for label, label_data in grouped_data:\n",
    "  print(f\"\\nLabel: {label}\")\n",
    "  print(label_data.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop column\n",
    "columns_to_drop = ['src_ip', 'dst_ip']\n",
    "dataset = dataset.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop column\n",
    "columns_to_drop = ['tos', 'flags', 'offset', 'code_icmp', 'rx_error_ave', 'rx_dropped_ave', 'tx_error_ave', 'tx_dropped_ave']\n",
    "dataset = dataset.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        datapath_id  version  header_length  total_length  ttl  proto   csum  \\\n",
      "215082            1        4              5            40  250      6  54748   \n",
      "257626            1        4              5            40  250      6  17009   \n",
      "171384            1        4              5            55   64     17  50100   \n",
      "314223            1        4              5            41   64     17  26302   \n",
      "539809            1        4              5            28   64      1  26334   \n",
      "...             ...      ...            ...           ...  ...    ...    ...   \n",
      "596692            1        4              5            28   64      1  26335   \n",
      "507939            1        4              5            55   64     17  39627   \n",
      "306604            1        4              5            28   64      1  26330   \n",
      "432899            1        4              5            55   64     17  29416   \n",
      "282251            1        4              5            55   64     17  61459   \n",
      "\n",
      "        src_port  dst_port  tcp_flag  type_icmp  csum_icmp  port_no  \\\n",
      "215082       318        80         2          8      63016        1   \n",
      "257626       729        80         2          8      63016        1   \n",
      "171384       933       161         2          8      63268        1   \n",
      "314223       880      1008         8          8      63395        1   \n",
      "539809       560       161         2          8      63163        1   \n",
      "...          ...       ...       ...        ...        ...      ...   \n",
      "596692       536       161         2          8      63119        1   \n",
      "507939       267       161         2          8      63268        1   \n",
      "306604       560       161         2          8      63215        1   \n",
      "432899       779       161         2          8      63016        1   \n",
      "282251       703       161         2          8      63016        1   \n",
      "\n",
      "        rx_bytes_ave  tx_bytes_ave  label  \n",
      "215082            44           115      2  \n",
      "257626            46           113      2  \n",
      "171384            49           115      3  \n",
      "314223            52           112      6  \n",
      "539809            54           113      4  \n",
      "...              ...           ...    ...  \n",
      "596692            54           113      4  \n",
      "507939            53           115      3  \n",
      "306604            54           113      4  \n",
      "432899            53           113      3  \n",
      "282251            54           113      3  \n",
      "\n",
      "[120000 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# Pada kolom class, dataset masih memiliki tipe kategorial.\n",
    "# Rubah menjadi data numerik untuk proses tahap selanjutnya.\n",
    "dataset = dataset.replace(\n",
    "{\"label\": {\"DDOS_ICMP\": 1, \"DDOS_TCP\": 2, \"DDOS_UDP\": 3, \"NORMAL_ICMP\": 4, \"NORMAL_TCP\": 5, \"NORMAL_UDP\": 6}})\n",
    "print(dataset.sample(frac=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout score:  0.99985\n"
     ]
    }
   ],
   "source": [
    "#Metode Holdout\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Memisahkan fitur dataset (X) dan class/label dataset (y)\n",
    "X = dataset.drop('label', axis=1) # or using X = dataset.drop('class', axis=1)\n",
    "y = dataset['label'] # or using y = dataset['class']\n",
    "# random_state=1 artinya tanpa random\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "# Menset model ke model yang dipilih dan mem‐fit modelnya\n",
    "# model dapat diganti secara manual\n",
    "model = KNeighborsClassifier(n_neighbors=3) # algortima klasifikasi Nearest Neighbor\n",
    "# Melatih (fit) model menggunakan X_train, y_train data\n",
    "model.fit(X_train, y_train)\n",
    "# Menghitung dan mencetak akurasi model dengan metode Holdout\n",
    "modelScore = model.score(X_test, y_test)\n",
    "print(\"Holdout score: \", modelScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Subsampling score:  0.9997666666666667\n"
     ]
    }
   ],
   "source": [
    "#Random Subsampling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Memisahkan fitur dataset (X) dan class/label dataset (y)\n",
    "X = dataset.drop('label', axis=1) # or using X = dataset.drop('class', axis=1)\n",
    "y = dataset['label'] # or using y = dataset['class'\n",
    "# random_state=42 is for reproducility artinya random level 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Menset model ke model yang dipilih dan mem‐fit modelnya\n",
    "# model dapat diganti secara manual\n",
    "model = KNeighborsClassifier(n_neighbors=3) # algortima klasifikasi Nearest Neighbor\n",
    "# Melatih (fit) model menggunakan X_train, y_train data\n",
    "model.fit(X_train, y_train)\n",
    "# Menghitung dan mencetak akurasi model dengan metode Random Subsampling (random_state=42)\n",
    "modelScore = model.score(X_test, y_test)\n",
    "print(\"Random Subsampling score: \", modelScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K‐Fold Cross Validation score:  [0.99998333 0.99991667 0.99996667 0.99993333 0.99993333 0.99991667\n",
      " 0.9999     0.99998333 0.99991667 0.9999    ]\n",
      "Ratas KFCV score:  0.9999350000000001\n",
      "K‐Fold Cross Validation MAE:  [-1.66666667e-05 -8.33333333e-05 -3.33333333e-05 -6.66666667e-05\n",
      " -6.66666667e-05 -8.33333333e-05 -1.00000000e-04 -1.66666667e-05\n",
      " -8.33333333e-05 -1.00000000e-04]\n",
      "Ratas KFCV Mean Absolute Error:  -6.500000000000001e-05\n",
      "K‐Fold Cross Validation RMSE:  [-1.66666667e-05 -8.33333333e-05 -3.33333333e-05 -6.66666667e-05\n",
      " -6.66666667e-05 -8.33333333e-05 -1.00000000e-04 -1.66666667e-05\n",
      " -8.33333333e-05 -1.00000000e-04]\n",
      "Ratas KFCV Root Mean Square Error:  -6.500000000000001e-05\n"
     ]
    }
   ],
   "source": [
    "#K‐Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "# Memisahkan fitur dataset (X) dan class/label dataset (y)\n",
    "X = dataset.drop('label', axis=1) # or using X = dataset.drop('class', axis=1)\n",
    "y = dataset['label'] # or using y = dataset['class'\n",
    "# Menset model ke model yang dipilih dan mem‐fit modelnya\n",
    "# model dapat diganti secara manual\n",
    "model = KNeighborsClassifier(n_neighbors=3) # algortima klasifikasi Nearest Neighbor\n",
    "# Menghitung dan mencetak akurasi model\n",
    "kFoldValidation = KFold(10)\n",
    "modelScore = cross_val_score(model, X, y, cv=kFoldValidation)\n",
    "print(\"K‐Fold Cross Validation score: \", modelScore) # hasilnya score sebanyak K\n",
    "print(\"Ratas KFCV score: \", np.mean(modelScore)) # menghitung ratas score dari score sejumlah K\n",
    "\"\"\"\n",
    "Kadang kala diperlukan ukuran error dari model sebagai kebalikan dari ukuran akurasi.\n",
    "Berikut ini adalah menghitung error menggunakan MEA dan RMSE\n",
    "\"\"\"\n",
    "# Menghitung dan mencetak Mean Absolute Error (MAE) model\n",
    "maeScore = cross_val_score(model, X, y, cv=kFoldValidation, scoring='neg_mean_absolute_error')\n",
    "print(\"K‐Fold Cross Validation MAE: \", maeScore) # hasilnya mae sebanyak K\n",
    "print(\"Ratas KFCV Mean Absolute Error: \", np.mean(maeScore)) # menghitung ratas mae dari mae sejumlah K\n",
    "# # Menghitung dan mencetak Root Mean Square Error (RMSE) model\n",
    "rmseScore = cross_val_score(model, X, y, cv=kFoldValidation, scoring='neg_mean_squared_error')\n",
    "print(\"K‐Fold Cross Validation RMSE: \", rmseScore) # hasilnya rmse sebanyak K\n",
    "print(\"Ratas KFCV Root Mean Square Error: \", np.mean(rmseScore)) # menghitung ratas rmse dari mae sejumlah K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Menghitung dan mencetak akurasi model\u001b[39;00m\n\u001b[0;32m     14\u001b[0m LOO_validation \u001b[38;5;241m=\u001b[39m LeaveOneOut()\n\u001b[1;32m---> 15\u001b[0m modelScore \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOO_validation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOOCV score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, modelScore) \u001b[38;5;66;03m# hasilnya array prediksi yaitu 1=benar dan 0=salah\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRatas LOOCV score: \u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(modelScore)) \u001b[38;5;66;03m# menghitung ratas score dari score sejumlah benar & salah\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\raiha\\anaconda3\\envs\\myenv1\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\raiha\\anaconda3\\envs\\myenv1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\raiha\\anaconda3\\envs\\myenv1\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\raiha\\anaconda3\\envs\\myenv1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\raiha\\anaconda3\\envs\\myenv1\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\raiha\\anaconda3\\envs\\myenv1\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\raiha\\anaconda3\\envs\\myenv1\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\raiha\\anaconda3\\envs\\myenv1\\lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\raiha\\anaconda3\\envs\\myenv1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\raiha\\anaconda3\\envs\\myenv1\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\raiha\\anaconda3\\envs\\myenv1\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:238\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# KNeighborsClassifier.metric is not validated yet\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    219\u001b[0m )\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m        The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#LeaveOneOut\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "# Memisahkan fitur dataset (X) dan class/label dataset (y)\n",
    "X = dataset.drop('label', axis=1) # or using X = dataset.drop('class', axis=1)\n",
    "y = dataset['label'] # or using y = dataset['class'\n",
    "# Menset model ke model yang dipilih dan mem‐fit modelnya\n",
    "# model dapat diganti secara manual\n",
    "model = KNeighborsClassifier(n_neighbors=3) # algortima klasifikasi Nearest Neighbor\n",
    "# Menghitung dan mencetak akurasi model\n",
    "LOO_validation = LeaveOneOut()\n",
    "modelScore = cross_val_score(model, X, y, cv=LOO_validation)\n",
    "print(\"LOOCV score: \", modelScore) # hasilnya array prediksi yaitu 1=benar dan 0=salah\n",
    "print(\"Ratas LOOCV score: \", np.mean(modelScore)) # menghitung ratas score dari score sejumlah benar & salah\n",
    "\"\"\"\n",
    "Kadang kala diperlukan ukuran error dari model sebagai kebalikan dari ukuran akurasi.\n",
    "Berikut ini adalah menghitung error menggunakan MEA dan RMSE \"\"\"\n",
    "# Menghitung dan mencetak Mean Absolute Error (MAE) model\n",
    "maeScore = cross_val_score(model, X, y, cv=LOO_validation, scoring='neg_mean_absolute_error')\n",
    "print(\"LOOCV MAE: \", maeScore) # hasilnya mae sebanyak K\n",
    "print(\"Ratas LOOCV Mean Absolute Error: \", np.mean(maeScore)) # menghitung ratas mae dari mae sejumlah K\n",
    "# # Menghitung dan mencetak Root Mean Square Error (RMSE) model\n",
    "rmseScore = cross_val_score(model, X, y, cv=LOO_validation, scoring='neg_mean_squared_error')\n",
    "print(\"LOOCV Cross Validation RMSE: \", rmseScore) # hasilnya rmse sebanyak K\n",
    "print(\"Ratas LOOCV Root Mean Square Error: \", np.mean(rmseScore)) # menghitung ratas rmse dari mae sejumlah K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Prepare training and test sets\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     train \u001b[38;5;241m=\u001b[39m resample(values, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_samples\u001b[38;5;241m=\u001b[39mn_size, random_state\u001b[38;5;241m=\u001b[39mi)  \u001b[38;5;66;03m# Different random state for each iteration\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m values \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m train\u001b[38;5;241m.\u001b[39mtolist()])\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     model \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# K-Nearest Neighbors classifier\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 19\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Prepare training and test sets\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     train \u001b[38;5;241m=\u001b[39m resample(values, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_samples\u001b[38;5;241m=\u001b[39mn_size, random_state\u001b[38;5;241m=\u001b[39mi)  \u001b[38;5;66;03m# Different random state for each iteration\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m values \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m train\u001b[38;5;241m.\u001b[39mtolist()])\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     model \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# K-Nearest Neighbors classifier\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample  # for Bootstrap sampling\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'dataset' is your DataFrame containing the data\n",
    "# Convert dataset to array\n",
    "values = dataset.values\n",
    "\n",
    "# Configure Bootstrap\n",
    "n_iterations = 10  # Number of bootstrap samples to create\n",
    "n_size = int(len(dataset) * 0.5)  # Size of each bootstrap sample (50% of the dataset)\n",
    "\n",
    "# Run Bootstrap\n",
    "stats = []\n",
    "for i in range(n_iterations):\n",
    "    # Prepare training and test sets\n",
    "    train = resample(values, replace=True, n_samples=n_size, random_state=i)  # Different random state for each iteration\n",
    "    test = np.array([x for x in values if x.tolist() not in train.tolist()])\n",
    "\n",
    "    # Fit model\n",
    "    model = KNeighborsClassifier(n_neighbors=3)  # K-Nearest Neighbors classifier\n",
    "    model.fit(train[:, :-1], train[:, -1])  # Train the model with training data\n",
    "\n",
    "    # Evaluate model\n",
    "    predictions = model.predict(test[:, :-1])  # Predict on the test data\n",
    "    score = accuracy_score(test[:, -1], predictions)  # Calculate accuracy score\n",
    "    stats.append(score)\n",
    "\n",
    "# Print results of all bootstrap trials\n",
    "print(\"Hasil semua percobaan bootstrap: \", stats)\n",
    "print(\"Rata-rata Bootstrap score: \", np.mean(stats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Run Bootstrap iterations in parallel\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbootstrap_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# End timing\u001b[39;00m\n\u001b[0;32m     34\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\raiha\\anaconda3\\envs\\myenv1\\lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\raiha\\anaconda3\\envs\\myenv1\\lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\raiha\\anaconda3\\envs\\myenv1\\lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Convert dataset to array\n",
    "values = dataset.values\n",
    "\n",
    "# Configure Bootstrap\n",
    "n_iterations = 1  # Number of bootstrap samples to create\n",
    "n_size = int(len(dataset) * 0.1)  # Size of each bootstrap sample (50% of the dataset)\n",
    "\n",
    "# Function to perform one bootstrap iteration\n",
    "def bootstrap_iteration(i):\n",
    "    train = resample(values, replace=True, n_samples=n_size, random_state=i)\n",
    "    test = np.array([x for x in values if x.tolist() not in train.tolist()])\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=3, algorithm='kd_tree')\n",
    "    model.fit(train[:, :-1], train[:, -1])\n",
    "\n",
    "    predictions = model.predict(test[:, :-1])\n",
    "    score = accuracy_score(test[:, -1], predictions)\n",
    "    return score\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Run Bootstrap iterations in parallel\n",
    "stats = Parallel(n_jobs=-1)(delayed(bootstrap_iteration)(i) for i in range(n_iterations))\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Print results of all bootstrap trials\n",
    "print(\"Hasil semua percobaan bootstrap: \", stats)\n",
    "print(\"Rata-rata Bootstrap score: \", np.mean(stats))\n",
    "print(\"Total time: \", end_time - start_time, \"seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
